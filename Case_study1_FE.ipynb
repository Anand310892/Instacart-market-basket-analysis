{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3657,
     "status": "ok",
     "timestamp": 1612160563164,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "fW6IW-PoF2aN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import lightgbm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "#!pip3 install dask[complete]\n",
    "#import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets here to form large datasets master_prior and master_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9RjHqJWI33hV"
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"products.csv\")\n",
    "aisles = pd.read_csv(\"aisles.csv\")\n",
    "departments = pd.read_csv(\"departments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FiVlxT3M4npv"
   },
   "outputs": [],
   "source": [
    "Products_aisles_departments= pd.merge(products,aisles,on='aisle_id')\n",
    "Products_aisles_departments=pd.merge(Products_aisles_departments,departments,on='department_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IX_B7XObIXgo"
   },
   "outputs": [],
   "source": [
    "orders_and_prior=pd.merge(orders,order_products__prior,on='order_id')\n",
    "orders_and_train=pd.merge(orders,order_products__train,on='order_id')\n",
    "master_train=pd.merge(orders_and_train,Products_aisles_departments,on='product_id')\n",
    "master_prior=pd.merge(orders_and_prior,Products_aisles_departments,on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_prior.to_csv('master_prior.csv',index=False)\n",
    "master_train.to_csv('master_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged data is saved and then loaded in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 107564,
     "status": "ok",
     "timestamp": 1612160812995,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "h7aic7Fw9q9z"
   },
   "outputs": [],
   "source": [
    "master_train=pd.read_csv('master_train.csv')\n",
    "master_prior=pd.read_csv('master_prior.csv')\n",
    "#orders=pd.read_csv(\"orders.csv\")\n",
    "#order_products__prior=pd.read_csv(\"order_products__prior.csv\")\n",
    "#order_products__train=pd.read_csv(\"order_products__train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the features created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_78_features=pd.read_csv('final_78_features.csv')\n",
    "feature_data_test=pd.read_csv('feature_data_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test and train users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2212,
     "status": "ok",
     "timestamp": 1612160914875,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "UWsCO4UnW5gy"
   },
   "outputs": [],
   "source": [
    "test_users=pd.unique(orders[orders['eval_set']=='test']['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1421,
     "status": "ok",
     "timestamp": 1612160914876,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "huNWxUSxXEkd"
   },
   "outputs": [],
   "source": [
    "train_users=pd.unique(orders[orders['eval_set']=='train']['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_prior.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_prior.drop(['days_since_prior_order'],axis=1).isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It is clear that only 'days_since_prior_order' contains null values. These nulls values are assigned when orders placed for the first time . I will  take care of this while featurizing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format='{:.5f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_number</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>order_dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30356421.00000</td>\n",
       "      <td>30356421.00000</td>\n",
       "      <td>30356421.00000</td>\n",
       "      <td>30356421.00000</td>\n",
       "      <td>30356421.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.24706</td>\n",
       "      <td>8.35415</td>\n",
       "      <td>11.10407</td>\n",
       "      <td>13.41125</td>\n",
       "      <td>2.74078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.59170</td>\n",
       "      <td>7.13354</td>\n",
       "      <td>8.77891</td>\n",
       "      <td>4.24682</td>\n",
       "      <td>2.08792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.00000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.00000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>5.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.00000</td>\n",
       "      <td>145.00000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        order_number  add_to_cart_order  days_since_prior_order  \\\n",
       "count 30356421.00000     30356421.00000          30356421.00000   \n",
       "mean        18.24706            8.35415                11.10407   \n",
       "std         17.59170            7.13354                 8.77891   \n",
       "min          2.00000            1.00000                 0.00000   \n",
       "25%          6.00000            3.00000                 5.00000   \n",
       "50%         12.00000            6.00000                 8.00000   \n",
       "75%         25.00000           11.00000                15.00000   \n",
       "max         99.00000          145.00000                30.00000   \n",
       "\n",
       "       order_hour_of_day      order_dow  \n",
       "count     30356421.00000 30356421.00000  \n",
       "mean            13.41125        2.74078  \n",
       "std              4.24682        2.08792  \n",
       "min              0.00000        0.00000  \n",
       "25%             10.00000        1.00000  \n",
       "50%             13.00000        3.00000  \n",
       "75%             16.00000        5.00000  \n",
       "max             23.00000        6.00000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_prior.dropna(axis=0)[['order_number','add_to_cart_order','days_since_prior_order','order_hour_of_day','order_dow']].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data looks clean as there are no missing values('only present in 'days_since_prior_order') which will be handled while doing feature engineering. There does not look like any outliers apart from add_to_cart_order where max is 145..But we keep this data as 145 add_cart_order_number is a possible value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization starts from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3189,
     "status": "ok",
     "timestamp": 1612160923146,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "8zC-1mj0K0QP"
   },
   "outputs": [],
   "source": [
    "product_name_count = master_prior['product_id'].value_counts()\n",
    "aisle_count = master_prior['aisle_id'].value_counts()\n",
    "department_count = master_prior['department_id'].value_counts()\n",
    "product_freq_ratio=product_name_count/(master_prior['product_id'].shape[0])\n",
    "aisle_freq_ratio=aisle_count/(master_prior['aisle_id'].shape[0])\n",
    "department_freq_ratio=department_count/(master_prior['department_id'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2824,
     "status": "ok",
     "timestamp": 1612160926646,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "n6a-OB1jQNqK"
   },
   "outputs": [],
   "source": [
    "dep_reorder_ratio   = master_prior.groupby([\"department_id\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
    "aisle_reorder_ratio = master_prior.groupby([\"aisle_id\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
    "product_reorder_ratio = master_prior.groupby([\"product_id\"])[\"reordered\"].aggregate(\"mean\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2822,
     "status": "ok",
     "timestamp": 1612160926647,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "q8WECQYfm6Ad"
   },
   "outputs": [],
   "source": [
    "dep_reorder_ratio=dep_reorder_ratio.set_index('department_id')\n",
    "aisle_reorder_ratio=aisle_reorder_ratio.set_index('aisle_id')\n",
    "product_reorder_ratio=product_reorder_ratio.set_index('product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3999,
     "status": "ok",
     "timestamp": 1612160928432,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "FcWj7H_-fcRA"
   },
   "outputs": [],
   "source": [
    "reorder_ratio_cart_universal = master_prior.groupby([\"add_to_cart_order\"])[\"reordered\"].aggregate(\"mean\")\n",
    "product_add_order_universal  =master_prior[['product_id','add_to_cart_order']].groupby(['product_id']).aggregate(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4246,
     "status": "ok",
     "timestamp": 1612160929513,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "I8eKnB-xiu68"
   },
   "outputs": [],
   "source": [
    "all_user_reorder_ratio_hour = master_prior.groupby([\"order_hour_of_day\"])[\"reordered\"].aggregate(\"mean\")\n",
    "product_ordering_hour       =  master_prior[['product_id','order_hour_of_day']].groupby(['product_id']).aggregate(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3372,
     "status": "ok",
     "timestamp": 1612160929513,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "Eydm8JIaiy5A"
   },
   "outputs": [],
   "source": [
    "mini_master_train=master_train[['user_id','product_id','order_number','order_dow','order_hour_of_day','days_since_prior_order','reordered']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting train and test users for multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users_list=[]\n",
    "train_users_list.append(train_user2[0:6300])\n",
    "train_users_list.append(train_user2[6300:12600])\n",
    "train_users_list.append(train_user2[12600:18900])\n",
    "train_users_list.append(train_user2[18900:25200])\n",
    "train_users_list.append(train_user2[25200:31500])\n",
    "train_users_list.append(train_user2[31500:37800])\n",
    "train_users_list.append(train_user2[37800:44100])\n",
    "train_users_list.append(train_user2[44100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users_list = []\n",
    "test_users_list.append(test_users[0:9400])\n",
    "test_users_list.append(test_users[9400:18800])\n",
    "test_users_list.append(test_users[18800:28200])\n",
    "test_users_list.append(test_users[28200:37600])\n",
    "test_users_list.append(test_users[37600:47000])\n",
    "test_users_list.append(test_users[47000:56400])\n",
    "test_users_list.append(test_users[56400:65800])\n",
    "test_users_list.append(test_users[65800:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process to create the features; The below firstprocess function is created to design features and to use with multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st set of feaures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1484,
     "status": "ok",
     "timestamp": 1611982629145,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "OQdodvOXpsH-",
    "outputId": "127d2654-86c2-4086-84c0-7c69b49b1c38"
   },
   "source": [
    "<ol>\n",
    "<li>max_order_number = latest order number ordered by the user </li>\n",
    "<li>avg_products_per_order5 = average number of products ordered in user's last five orders</li>\n",
    "<li>avg_products_per_ordered = average number of products per order </li>\n",
    "<li>avg_times_product =  number of  times a product is ordered on an average by the user</li>\n",
    "<li>max_times_product  =  maximun times any product is ordered by the user</li>\n",
    "<li>max_reorder_any_product = maximum reorder ratio of any product by the user;Here reorders refers number of reorders in user's total orders</li>\n",
    "    \n",
    "<li>reorder_ratio = total reorder ratio of that product</li>\n",
    "    \n",
    "<li>product_add_order_universal = product's all user average add to cart number</li>\n",
    "<li>reorder_ratio_cart_universal = for a perticular add to cart number what is the reorder ratio for all users</li>\n",
    "    \n",
    "<li>product_add_order_local = what is the product's mean add_to_cart_order number for a perticular user?</li>\n",
    "<li>reorder_ratio_cart_local = For a perticular user and perticular add to cart number what is the reorder ratio?</li>\n",
    "    \n",
    "<li>product_time_order = Usually at what time product is ordered for all users</li>\n",
    "<li>order_dow = what day of the week user ordered</li>\n",
    "<li> order_hour_of_day = In which hour user ordered</li>\n",
    "<li> days_since_prior_order = how many days elapsed since last order</li>\n",
    "    \n",
    "<li>reorder_ratio_user_hour = what is the reorder ratio of the user at a perticular hour</li>\n",
    "<li>reorder_ratio_all_user_hour = how much in ratio all users order at a perticular hour</li>\n",
    "<li>reorder_ratio_user_week = how much in ratio user reorders on a perticular day of the week</li>\n",
    "<li>order_ratio=ratio of how many times user bought the product in his total orders</li>\n",
    "\n",
    "<li>department_id of the product</li>\n",
    "<li>aisle_id of the product</li>\n",
    "<li>pf= product frequency,ie it indicates the ratio of perticular product count to all product count</li>\n",
    "<li>af= (similar to product frequency)aisle frequency</li>\n",
    "<li>df =(similar to product frequency)department frequency</li>\n",
    "<li>dep_reorder_ratio=Reorder ratio of a perticular department for all users</li>\n",
    "<li>aisle_reorder_ratio=Reorder ratio of a perticular aisle for all users</li>\n",
    "<li>product_reorder_ratio=Reorder ratio of a perticular product for all users</li>\n",
    "<li>ordered_last_5 = how many times user ordered product in his last five orders</li>\n",
    "<li>atco = product's average add to cart order in users last 5 orders</li>\n",
    "<li>dspo = number of days it took to order this product from previous order of any product</li>\n",
    "<li>ohod = average order hour in last few orders</li>\n",
    "<li>odow = average day of week order was placed  in last few orders</li>\n",
    "<li>max_no_purchase = maximum number of days spent without buying, by the user.</li>\n",
    "<li>tot_chance_buy = once a perticular product is bought for the first time how orders user did?</li>\n",
    "<li>median_n5 = Median number of days user has gone without buying the product after the previous order</li>\n",
    "<li>order_steak_5='bin1',bin2','bin3,'bin4','bin5','bin6'= 'ordered'  or  'not ordered' product binary sequence in last five orders</li>\n",
    "<li>bin2dec= decimal reprecentation of the previous feature(order_steak_5)</li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature_creating_machine for Train set1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343259,
     "status": "ok",
     "timestamp": 1612161281190,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "WZ2Ft5yUbvAC",
    "outputId": "b0df04ae-3cf7-45ea-eddf-c0b1e294c747"
   },
   "outputs": [],
   "source": [
    "def firstprocess(train_users,i):\n",
    "    row_data=[]\n",
    "    for uid in tqdm(train_users):\n",
    "        max_order=orders[orders['user_id']==uid].order_number.max()\n",
    "        new_temp_orders=orders[(orders['user_id']==uid) & (orders['order_number'] == max_order)][['order_dow','order_hour_of_day','days_since_prior_order']]\n",
    "        #12\n",
    "        order_dow = int(new_temp_orders['order_dow'])\n",
    "        #13\n",
    "        order_hour_of_day = int(new_temp_orders['order_hour_of_day'])\n",
    "        #14\n",
    "        days_since_prior_order = int(new_temp_orders['days_since_prior_order'])\n",
    "\n",
    "        oneuser=master_prior[master_prior['user_id']==uid]\n",
    "        pids = pd.unique(oneuser['product_id'])\n",
    "\n",
    "        reorder_ratio_hour_user = oneuser.groupby([\"order_hour_of_day\"])[\"reordered\"].aggregate(\"mean\")\n",
    "        #1\n",
    "        max_order_number = oneuser['order_number'].max()\n",
    "        #2\n",
    "        avg_products_per_order5=oneuser['order_number'].value_counts(sort=False).values[-5:].mean()\n",
    "        #3\n",
    "        avg_pro_order=oneuser['order_number'].value_counts().mean()\n",
    "        #4\n",
    "        avg_times_pro=oneuser['product_id'].value_counts().mean()\n",
    "        #5\n",
    "        max_times_pro = oneuser['product_id'].value_counts().max()\n",
    "\n",
    "        latest=oneuser['order_number'].max()-5\n",
    "        latest=oneuser[oneuser['order_number']>latest]\n",
    "        #6\n",
    "        max_reorder_ratio=(latest[['product_id','order_number']].groupby(['product_id']).count()/5).values.max()\n",
    "        #7\n",
    "        reorder_ratio=np.count_nonzero((oneuser['reordered']))/oneuser['reordered'].shape[0]\n",
    "  \n",
    "        \n",
    "        #8\n",
    "        product_add_order_local  = oneuser[['product_id','add_to_cart_order']].groupby(['product_id']).aggregate(\"mean\")\n",
    "        \n",
    "        #9\n",
    "        reorder_ratio_cart_local = oneuser.groupby([\"add_to_cart_order\"])[\"reordered\"].aggregate(\"mean\")\n",
    "\n",
    "        #10\n",
    "        one_user_reorder_ratio_hour = oneuser.groupby([\"order_hour_of_day\"])[\"reordered\"].aggregate(\"mean\")\n",
    "        #11\n",
    "        one_user_reorder_ratio_week = oneuser.groupby([\"order_dow\"])[\"reordered\"].aggregate(\"mean\")\n",
    "  \n",
    "        user_tot_order=np.arange(1,oneuser['order_number'].max()+1)\n",
    "        #another feature related above one comes here\n",
    "        if order_hour_of_day in one_user_reorder_ratio_hour.index:\n",
    "            reorder_ratio_user_hour=one_user_reorder_ratio_hour.loc[order_hour_of_day]\n",
    "        else:\n",
    "            reorder_ratio_user_hour=0\n",
    "        #15\n",
    "        reorder_ratio_all_user_hour = all_user_reorder_ratio_hour.loc[order_hour_of_day]\n",
    "        if order_dow in one_user_reorder_ratio_week.index:\n",
    "            reorder_ratio_user_week = one_user_reorder_ratio_week.loc[order_dow]\n",
    "        else:\n",
    "            reorder_ratio_user_week = 0\n",
    "        \n",
    "        for pid in pids:\n",
    "            feature=[]\n",
    "            temp_train=mini_master_train[(mini_master_train['user_id']==uid) & (mini_master_train['product_id']==pid)]\n",
    "    \n",
    "            oneuserproduct=oneuser[oneuser['product_id']==pid]\n",
    "    \n",
    "            user_pro_order=pd.unique(oneuserproduct['order_number'])\n",
    "            order_steak=['1' if i in user_pro_order  else '0' for i in user_tot_order]\n",
    "            #16\n",
    "            order_steak_5=order_steak[-5:]\n",
    "            if(len(order_steak_5)<5):\n",
    "                order_steak_5=1*['0']+order_steak_5\n",
    "            #17\n",
    "            bin2dec=int(''.join(order_steak_5),2)\n",
    "    \n",
    "            #User feature\n",
    "    \n",
    "            p_add_order_universal = int(product_add_order_universal.loc[pid])\n",
    "            reorder_ratio_universal = reorder_ratio_cart_universal.loc[p_add_order_universal]\n",
    "\n",
    "\n",
    "\n",
    "            p_add_order_local = int(product_add_order_local.loc[pid])\n",
    "            if p_add_order_local in reorder_ratio_cart_local.index:\n",
    "                reorder_ratio_local = reorder_ratio_cart_local.loc[p_add_order_local]\n",
    "            else:\n",
    "                reorder_ratio_local=0\n",
    "            product_time_order = int(product_ordering_hour.loc[pid])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #product features\n",
    "            order_ratio=len(user_pro_order)/len(user_tot_order)\n",
    "\n",
    "            department_id=oneuserproduct.iloc[0]['department_id']\n",
    "            aisle_id=oneuserproduct.iloc[0]['aisle_id']\n",
    "\n",
    "            pf=product_freq_ratio[pid]\n",
    "            af=aisle_freq_ratio[aisle_id]\n",
    "            df=department_freq_ratio[department_id]\n",
    "\n",
    "            order_steak_5=[int(i) for i in order_steak_5]\n",
    "\n",
    "            ordered_last_5=np.count_nonzero(order_steak_5)\n",
    "\n",
    "            atco=oneuserproduct['add_to_cart_order'].tail().mean()\n",
    "            dspo=oneuserproduct['days_since_prior_order'].tail().mean()\n",
    "            ohod=oneuserproduct['order_hour_of_day'].tail().mean()\n",
    "            odow=oneuserproduct['order_dow'].tail().mean()\n",
    "\n",
    "            max_no_purchase=oneuserproduct['days_since_prior_order'].tail().max() \n",
    "\n",
    "    \n",
    "            tot_chance_buy=len(order_steak)-order_steak.index('1')\n",
    "\n",
    "            median_n5=np.median(oneuserproduct['days_since_prior_order'].tail())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            feature.append(uid)\n",
    "            feature.append(pid)\n",
    "            #Users\n",
    "            feature.append(max_order_number)\n",
    "            feature.append(avg_products_per_order5)\n",
    "  \n",
    "            feature.append(np.round(avg_pro_order,4))\n",
    "\n",
    "            feature.append(np.round(avg_times_pro,4))\n",
    "\n",
    "            feature.append(max_times_pro)\t\n",
    "\n",
    "            feature.append(np.round(max_reorder_ratio,4))\n",
    "\n",
    "            feature.append(np.round(reorder_ratio,3))\n",
    "    \n",
    "            feature.append(p_add_order_universal)\n",
    "            feature.append(np.round(reorder_ratio_universal,3))\n",
    "            feature.append(p_add_order_local)\n",
    "            feature.append(np.round(reorder_ratio_local,4))\n",
    "            feature.append(product_time_order)\n",
    "            if (temp_train.empty == False):\n",
    "                reordered = 1\n",
    "            else:\n",
    "                reordered=0\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "            feature.append(order_dow)\n",
    "            feature.append(order_hour_of_day)\n",
    "            feature.append(days_since_prior_order)\n",
    "\n",
    "            feature.append(np.round(reorder_ratio_user_hour,3))\n",
    "            feature.append(np.round(reorder_ratio_all_user_hour,3))\n",
    "            feature.append(np.round(reorder_ratio_user_week,3))\n",
    "            #products\n",
    "            feature.append(np.round(order_ratio,4))\n",
    "            feature.append(department_id)\n",
    "            feature.append(aisle_id)\n",
    "            feature.append(np.round(pf,3))\n",
    "            feature.append(np.round(af,3))\n",
    "            feature.append(np.round(df,3))\n",
    "            ##\n",
    "            feature.append(np.round(float(dep_reorder_ratio.loc[department_id]),4))\n",
    "            feature.append(np.round(float(aisle_reorder_ratio.loc[aisle_id]),4))\n",
    "            feature.append(np.round(float(product_reorder_ratio.loc[pid]),4))\n",
    "\n",
    "            feature.append(ordered_last_5)\n",
    "            feature.append(np.round(atco,4))\n",
    "            if(dspo!=dspo):\n",
    "                feature.append(0)\n",
    "            else:\n",
    "                feature.append(np.round(dspo,4))\n",
    "            feature.append(np.round(ohod,4))\n",
    "            feature.append(np.round(odow,4))\n",
    "            if(max_no_purchase!=max_no_purchase):\n",
    "                feature.append(0)\n",
    "            else:\n",
    "                feature.append(max_no_purchase)\n",
    "            feature.append(tot_chance_buy)\n",
    "            if(median_n5!=median_n5):\n",
    "                feature.append(0)\n",
    "            else:\n",
    "                feature.append(median_n5)\n",
    "\n",
    "            feature.extend(order_steak_5)\n",
    "\n",
    "    \n",
    "            feature.append(bin2dec)\n",
    "\n",
    "            feature.append(reordered)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            row_data.append(feature)\n",
    "    temp=pd.DataFrame(row_data,columns=columns37)\n",
    "    temp.to_csv('featured_data'+str(i)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st set of features for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s6B8qmqh458p"
   },
   "outputs": [],
   "source": [
    "columns12=['user_id','product_id','max_order_number','avg_products_per_ordered_5','avg_products_per_ordered','avg_times_product','max_times_product','max_reorder_any_product','total_reorder_ratio','product_add_order_universal','reorder_ratio_cart_universal','product_add_order_local','reorder_ratio_cart_local','product_time_order']\n",
    "\n",
    "columns25=['order_dow','order_hour_of_day','days_since_prior_order','reorder_ratio_user_hour','reorder_ratio_all_user_hour','reorder_ratio_user_week','order_ratio','department_id','aisle_id',\n",
    "         'pf','af','df','dep_reorder_ratio','aisle_reorder_ratio','product_reorder_ratio',\n",
    "         'ordered_last_5','atco','dspo','ohod','odow','max_no_purchase','tot_chance_buy','median_n5','bin1','bin2','bin3','bin4','bin5','bin2dec_order_steak5']\n",
    "columns37=columns12+columns25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343259,
     "status": "ok",
     "timestamp": 1612161281190,
     "user": {
      "displayName": "Anand Bhat",
      "photoUrl": "",
      "userId": "11921110568987694133"
     },
     "user_tz": -330
    },
    "id": "WZ2Ft5yUbvAC",
    "outputId": "b0df04ae-3cf7-45ea-eddf-c0b1e294c747"
   },
   "outputs": [],
   "source": [
    "def firstprocess(test_users,i):\n",
    "    row_data=[]\n",
    "    for uid in tqdm(test_users):\n",
    "        max_order=orders[orders['user_id']==uid].order_number.max()\n",
    "        new_temp_orders=orders[(orders['user_id']==uid) & (orders['order_number'] == max_order)][['order_dow','order_hour_of_day','days_since_prior_order']]\n",
    "        #12\n",
    "        order_dow = int(new_temp_orders['order_dow'])\n",
    "        #13\n",
    "        order_hour_of_day = int(new_temp_orders['order_hour_of_day'])\n",
    "        #14\n",
    "        days_since_prior_order = int(new_temp_orders['days_since_prior_order'])\n",
    "\n",
    "        oneuser=master_prior[master_prior['user_id']==uid]\n",
    "        pids = pd.unique(oneuser['product_id'])\n",
    "\n",
    "        reorder_ratio_hour_user = oneuser.groupby([\"order_hour_of_day\"])[\"reordered\"].aggregate(\"mean\")\n",
    "        #1\n",
    "        max_order_number = oneuser['order_number'].max()\n",
    "        #2\n",
    "        avg_products_per_order5=oneuser['order_number'].value_counts(sort=False).values[-5:].mean()\n",
    "        #3\n",
    "        avg_pro_order=oneuser['order_number'].value_counts().mean()\n",
    "        #4\n",
    "        avg_times_pro=oneuser['product_id'].value_counts().mean()\n",
    "        #5\n",
    "        max_times_pro = oneuser['product_id'].value_counts().max()\n",
    "\n",
    "        latest=oneuser['order_number'].max()-5\n",
    "        latest=oneuser[oneuser['order_number']>latest]\n",
    "        #6\n",
    "        max_reorder_ratio=(latest[['product_id','order_number']].groupby(['product_id']).count()/5).values.max()\n",
    "        #7\n",
    "        reorder_ratio=np.count_nonzero((oneuser['reordered']))/oneuser['reordered'].shape[0]\n",
    "  \n",
    "        #8\n",
    "        reorder_ratio_cart_local = oneuser.groupby([\"add_to_cart_order\"])[\"reordered\"].aggregate(\"mean\")\n",
    "        #9\n",
    "        product_add_order_local  = oneuser[['product_id','add_to_cart_order']].groupby(['product_id']).aggregate(\"mean\")\n",
    "\n",
    "        #10\n",
    "        one_user_reorder_ratio_hour = oneuser.groupby([\"order_hour_of_day\"])[\"reordered\"].aggregate(\"mean\")\n",
    "        #11\n",
    "        one_user_reorder_ratio_week = oneuser.groupby([\"order_dow\"])[\"reordered\"].aggregate(\"mean\")\n",
    "  \n",
    "        user_tot_order=np.arange(1,oneuser['order_number'].max()+1)\n",
    "        #another feature related above one comes here\n",
    "        if order_hour_of_day in one_user_reorder_ratio_hour.index:\n",
    "            reorder_ratio_user_hour=one_user_reorder_ratio_hour.loc[order_hour_of_day]\n",
    "        else:\n",
    "            reorder_ratio_user_hour=0\n",
    "        #15\n",
    "        reorder_ratio_all_user_hour = all_user_reorder_ratio_hour.loc[order_hour_of_day]\n",
    "        if order_dow in one_user_reorder_ratio_week.index:\n",
    "            reorder_ratio_user_week = one_user_reorder_ratio_week.loc[order_dow]\n",
    "        else:\n",
    "            reorder_ratio_user_week = 0\n",
    "        \n",
    "        for pid in pids:\n",
    "            feature=[]\n",
    "    \n",
    "            oneuserproduct=oneuser[oneuser['product_id']==pid]\n",
    "    \n",
    "            user_pro_order=pd.unique(oneuserproduct['order_number'])\n",
    "            order_steak=['1' if i in user_pro_order  else '0' for i in user_tot_order]\n",
    "            #16\n",
    "            order_steak_5=order_steak[-5:]\n",
    "            if(len(order_steak_5)<5):\n",
    "                order_steak_5=1*['0']+order_steak_5\n",
    "            #17\n",
    "            bin2dec=int(''.join(order_steak_5),2)\n",
    "    \n",
    "            #User feature\n",
    "    \n",
    "            p_add_order_universal = int(product_add_order_universal.loc[pid])\n",
    "            reorder_ratio_universal = reorder_ratio_cart_universal.loc[p_add_order_universal]\n",
    "\n",
    "\n",
    "\n",
    "            p_add_order_local = int(product_add_order_local.loc[pid])\n",
    "            if p_add_order_local in reorder_ratio_cart_local.index:\n",
    "                reorder_ratio_local = reorder_ratio_cart_local.loc[p_add_order_local]\n",
    "            else:\n",
    "                reorder_ratio_local=0\n",
    "            product_time_order = int(product_ordering_hour.loc[pid])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #product features\n",
    "            order_ratio=len(user_pro_order)/len(user_tot_order)\n",
    "\n",
    "            department_id=oneuserproduct.iloc[0]['department_id']\n",
    "            aisle_id=oneuserproduct.iloc[0]['aisle_id']\n",
    "\n",
    "            pf=product_freq_ratio[pid]\n",
    "            af=aisle_freq_ratio[aisle_id]\n",
    "            df=department_freq_ratio[department_id]\n",
    "\n",
    "            order_steak_5=[int(i) for i in order_steak_5]\n",
    "\n",
    "            ordered_last_5=np.count_nonzero(order_steak_5)\n",
    "\n",
    "            atco=oneuserproduct['add_to_cart_order'].tail().mean()\n",
    "            dspo=oneuserproduct['days_since_prior_order'].tail().mean()\n",
    "            ohod=oneuserproduct['order_hour_of_day'].tail().mean()\n",
    "            odow=oneuserproduct['order_dow'].tail().mean()\n",
    "\n",
    "            max_no_purchase=oneuserproduct['days_since_prior_order'].tail().max() \n",
    "\n",
    "    \n",
    "            tot_chance_buy=len(order_steak)-order_steak.index('1')\n",
    "\n",
    "            median_n5=np.median(oneuserproduct['days_since_prior_order'].tail())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            feature.append(uid)\n",
    "            feature.append(pid)\n",
    "            #Users\n",
    "            feature.append(max_order_number)\n",
    "            feature.append(avg_products_per_order5)\n",
    "  \n",
    "            feature.append(np.round(avg_pro_order,4))\n",
    "\n",
    "            feature.append(np.round(avg_times_pro,4))\n",
    "\n",
    "            feature.append(max_times_pro)\t\n",
    "\n",
    "            feature.append(np.round(max_reorder_ratio,4))\n",
    "\n",
    "            feature.append(np.round(reorder_ratio,3))\n",
    "    \n",
    "            feature.append(p_add_order_universal)\n",
    "            feature.append(np.round(reorder_ratio_universal,3))\n",
    "            feature.append(p_add_order_local)\n",
    "            feature.append(np.round(reorder_ratio_local,4))\n",
    "            feature.append(product_time_order)\n",
    "            \n",
    "            feature.append(order_dow)\n",
    "            feature.append(order_hour_of_day)\n",
    "            feature.append(days_since_prior_order)\n",
    "\n",
    "            feature.append(np.round(reorder_ratio_user_hour,3))\n",
    "            feature.append(np.round(reorder_ratio_all_user_hour,3))\n",
    "            feature.append(np.round(reorder_ratio_user_week,3))\n",
    "            #products\n",
    "            feature.append(np.round(order_ratio,4))\n",
    "            feature.append(department_id)\n",
    "            feature.append(aisle_id)\n",
    "            feature.append(np.round(pf,3))\n",
    "            feature.append(np.round(af,3))\n",
    "            feature.append(np.round(df,3))\n",
    "            ##\n",
    "            feature.append(np.round(float(dep_reorder_ratio.loc[department_id]),4))\n",
    "            feature.append(np.round(float(aisle_reorder_ratio.loc[aisle_id]),4))\n",
    "            feature.append(np.round(float(product_reorder_ratio.loc[pid]),4))\n",
    "\n",
    "            feature.append(ordered_last_5)\n",
    "            feature.append(np.round(atco,4))\n",
    "            if(dspo!=dspo):\n",
    "                feature.append(0)\n",
    "            else:\n",
    "                feature.append(np.round(dspo,4))\n",
    "            feature.append(np.round(ohod,4))\n",
    "            feature.append(np.round(odow,4))\n",
    "            if(max_no_purchase!=max_no_purchase):\n",
    "                feature.append(0)\n",
    "            else:\n",
    "                feature.append(max_no_purchase)\n",
    "            feature.append(tot_chance_buy)\n",
    "            if(median_n5!=median_n5):\n",
    "                feature.append(0)\n",
    "            else:\n",
    "                feature.append(median_n5)\n",
    "\n",
    "            feature.extend(order_steak_5)\n",
    "\n",
    "    \n",
    "            feature.append(bin2dec)\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            row_data.append(feature)\n",
    "    temp=pd.DataFrame(row_data,columns=columns37)\n",
    "    temp.to_csv('featured_data_test'+str(i)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 2nd set of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that Users products presence in all the orders is 0010101010, It means total 10 orders were place by the user till now. Out of which 3rd 5th and 7th and 9th orders conatain the product.<br>\n",
    "\n",
    "So in his last five orders, product's ordered or not ordered sequence is 01010 .That \n",
    "means User in his last five orders , ordered the product only in 2nd and 4th transaction\n",
    "\n",
    "\n",
    "<ol>\n",
    "    \n",
    "<li>ordere_ratio_last_5:It is just  order ratio : Indicating on how many orders in last 5 orders contain product.In the above example it is 2/5 </li>\n",
    "<li>count_of_ones_after_first_one:How many times product reordered after product is ordered in last 5 transaction . In the example it is 3. </li>\n",
    "<li>count_of_zeros_after_first_one:How many times product reordered after product is not ordered in last 5 transaction . In the example it is 4</li>\n",
    "<li>one_exceed_zeros_count:how many times product ordered exceeds not ordered after order of the product is placed for the first time.In the above example it is -1</li>\n",
    "<li>len_of_ordersteak_after_first_one:reorder_ratio_after_first_one:How many orders were there after product is placed for the first time . In the above example it is 7</li>\n",
    "<li>reorder_ratio_after_first_one:How many orders were there after product is placed for the first time . In the above example it is 7</li>\n",
    "<li>reorder_ratio_after_first_one:In the above example it is 3/7</li>\n",
    "<li>Is_it_reordered:This variables tells if the product is reordered atleast once after it is ordered for the first time.'1'='YES' for our example</li>\n",
    "<li>Is_the_first_one_last_order:Is the product ordered only in the previous order. Answer is 0 ='No' for our example, For sequence 0000001 answer is 'YES'</li>\n",
    "<li>Is_the_first_one_last_but_one_order : Is the product ordered only in the last but one order. Answer is 0 ='No' for our example,For sequence 00010 or 00011 it is 'YES'</li>\n",
    "<li>last_time_ordered:Wheather the product was ordered last time ,For our example it is 'NO'</li>\n",
    "<li>last_two_times_ordered:Wheather the product was ordered last two times ?</li>\n",
    "<li>coun_greater_2:Was the product reordered more than two times? 'YES' for our example</li>\n",
    "<li>coun_greater_3:Was the product reordered more than three times? 'YES' for our example</li>\n",
    "<li>first_index_of_one: What is the order number that the product was ordered for the first time? Answer=3</li>\n",
    "<li>orders_per_day: It is the ratio of total orders to number of days took to make these many orders </li>\n",
    "<li>days_taken_for_product_reorders_avg:It is average days took for the user to make reorder of the product since his first order of the product</li>\n",
    "<li>days_remain_to_probable_buy:For example for the current order for which our task is to predict the reorder,If the days elapsed since last order is 14 days and for user it takes on an average 16 days to reorder the product ; days remaing for probable buy is 2 </li>\n",
    "<li>ordperday_order_ratio:It is multiplication of number of orders made per day and order ratio;These are the previous features</li>\n",
    "<li>order_steak_days_weighted5_1:It is the weighted average of number of order units happend in the last 5  to total number of days taken in last five orders. Here More recent reorders of the product gets more weightage </li>\n",
    "<li>order_steak_days_weighted5_2:It is the weighted average of number of order units happend to total number of days taken to make number of orders once the product was ordered for the first time. Here More recent reorders of the product gets more weightage</li>\n",
    "<li>median_days_no_buy5:In the last five transaction median number of days spent withour buying the product since product is ordered for the first time</li>\n",
    "<li>max_days_no_buy5:In the last five transaction maximum number of days spent withour buying the product since product is ordered for the first time</li>\n",
    "<li>days_spent_no_buy_last:What is the number of days already elapsed till now withour buying the product since product is ordered for the last time</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstprocess(train_users,nocopy):\n",
    "    row_data=[]\n",
    "    for uid in tqdm(train_users):\n",
    "        \n",
    "        oneuser=master_prior[master_prior['user_id']==uid]\n",
    "        \n",
    "        train_order_number=orders[(orders['user_id']==uid)]['order_number'].max()\n",
    "        trains_days_since_prior_order=int(orders[(orders['user_id']==uid) & (orders.order_number==train_order_number)]['days_since_prior_order'])\n",
    "        pids = pd.unique(oneuser['product_id'])\n",
    "        \n",
    "        user_tot_order=np.arange(1,oneuser['order_number'].max()+1)\n",
    "        #another feature related above one comes here\n",
    "\n",
    "        \n",
    "        for pid in pids:\n",
    "            feature=[]\n",
    "            reordered=0\n",
    "            temp_train=mini_master_train[(mini_master_train['user_id']==uid) & (mini_master_train['product_id']==pid)]\n",
    "            \n",
    "            \n",
    "            oneuserproduct=oneuser[oneuser['product_id']==pid]\n",
    "    \n",
    "            user_pro_order=pd.unique(oneuserproduct['order_number'])\n",
    "            order_steak = [1 if i in user_pro_order  else 0 for i in user_tot_order]\n",
    "            \n",
    "\n",
    "            #product features\n",
    "            first_index_of_one=order_steak.index(1)\n",
    "            \n",
    "            order_steak_5=order_steak[-5:]\n",
    "            \n",
    "            order_steak_5=[int(i) for i in order_steak_5]\n",
    "\n",
    "            #\n",
    "            ordere_ratio_last_5=order_steak_5.count(1)/5\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            count_of_ones_after_first_one =order_steak.count(1)-1\n",
    "            count_of_zeros_after_first_one =order_steak[first_index_of_one:].count(0)\n",
    "            one_exceed_zeros_count=count_of_ones_after_first_one-count_of_zeros_after_first_one\n",
    "            len_of_ordersteak_after_first_one =len(order_steak[first_index_of_one:])\n",
    "            if(len_of_ordersteak_after_first_one!=0):\n",
    "                reorder_ratio_after_first_one = count_of_ones_after_first_one/len_of_ordersteak_after_first_one\n",
    "            else:\n",
    "                reorder_ratio_after_first_one=-0.5\n",
    "                \n",
    "            Is_it_reordered =order_steak[first_index_of_one:].count(1)-1\n",
    "            Is_the_first_one_last_order = 0\n",
    "            Is_the_first_one_last_but_one_order = 0\n",
    "            last_time_ordered=order_steak[-1:].count(1)\n",
    "            last_two_times_ordered=order_steak[-2:].count(1)\n",
    "            if(last_two_times_ordered==2):\n",
    "                last_two_times_ordered=1\n",
    "            else:\n",
    "                last_two_times_ordered=0\n",
    "    \n",
    "\n",
    "            if((len(order_steak)-1)==first_index_of_one):\n",
    "                Is_the_first_one_last_order=1\n",
    "            if((len(order_steak)-2)==first_index_of_one):\n",
    "                Is_the_first_one_last_but_one_order=1\n",
    "            \n",
    "            if(Is_it_reordered>=2):\n",
    "                coun_greater_2=1\n",
    "            else:\n",
    "                coun_greater_2=0\n",
    "            \n",
    "            \n",
    "            if(Is_it_reordered>=3):\n",
    "                coun_greater_3=1\n",
    "            else:\n",
    "                coun_greater_3=0\n",
    "\n",
    "            if(Is_it_reordered):\n",
    "            #find the sum of this with respect to all the products\n",
    "            #calculate total reorder probability here\n",
    "                Is_it_reordered=1\n",
    "            else:\n",
    "            #first time product only\n",
    "                Is_it_reordered=0\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            total_days_since_first_order=(oneuser.groupby(['order_number'])['days_since_prior_order'].aggregate('mean').reset_index().loc[first_index_of_one+1:]['days_since_prior_order'].sum())\n",
    "\n",
    "            if(total_days_since_first_order != 0):\n",
    "                orders_per_day=count_of_ones_after_first_one/total_days_since_first_order\n",
    "            else:\n",
    "                orders_per_day=-0.5\n",
    "\n",
    "    \n",
    "            if(count_of_ones_after_first_one != 0):\n",
    "                days_taken_for_product_reorders_avg = total_days_since_first_order/count_of_ones_after_first_one\n",
    "            else:\n",
    "                days_taken_for_product_reorders_avg=-0.5\n",
    "\n",
    "            if(days_taken_for_product_reorders_avg !=-0.5):\n",
    "                days_remain_to_probable_buy=int(days_taken_for_product_reorders_avg-trains_days_since_prior_order)\n",
    "            else:\n",
    "                days_remain_to_probable_buy = -0.5\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ordperday_order_ratio=orders_per_day*reorder_ratio_after_first_one\n",
    "            \n",
    "            days_list=orders[orders['user_id']==uid]['days_since_prior_order'].tolist()\n",
    "            days_list=days_list[1:][-5:]\n",
    "            order_steak5=order_steak[-5:]\n",
    "            \n",
    "            \n",
    "            if(sum(order_steak5)!=0):\n",
    "                first_occur_one=order_steak5.index(1)\n",
    "                if(sum(np.array(days_list)*0.01)!=0.0):\n",
    "                    order_steak_days_weighted5_1 = sum((np.arange(1,len(order_steak5)+1,1)/10)*order_steak5)/sum(np.array(days_list)*0.01)\n",
    "                else:\n",
    "                    order_steak_days_weighted5_1=-0.5\n",
    "                if(sum(np.array(days_list[first_occur_one:])*0.01) != 0.0):\n",
    "                    order_steak_days_weighted5_2 = sum((np.arange(1,len(order_steak5)+1,1)/10)*order_steak5)/sum(np.array(days_list[first_occur_one:])*0.01)\n",
    "                else:\n",
    "                    order_steak_days_weighted5_2=-0.5\n",
    "            else:\n",
    "                order_steak_days_weighted5_1=0\n",
    "                order_steak_days_weighted5_2=0\n",
    "                \n",
    "            \n",
    "            \n",
    "            listOfSumDays=[]\n",
    "            index_one=[i for i,j in enumerate(order_steak5) if j==1]\n",
    "            for i in range(len(index_one)):\n",
    "                k=index_one[i:i+2]\n",
    "                if(len(k)==2):\n",
    "                    \n",
    "                    listOfSumDays.append(sum(days_list[-5:][k[0]:k[1]]))\n",
    "                else:\n",
    "                    listOfSumDays.append(sum(days_list[-5:][k[0]:]))\n",
    "                    \n",
    "            if(len(listOfSumDays)!=0):\n",
    "                median_days_no_buy5=np.median(listOfSumDays)\n",
    "                max_days_no_buy5=np.max(listOfSumDays)\n",
    "                days_spent_no_buy_last=listOfSumDays[-1:][0]\n",
    "            else:\n",
    "                median_days_no_buy5=-0.5\n",
    "                max_days_no_buy5=-0.5\n",
    "                days_spent_no_buy_last=-0.5\n",
    "    \n",
    "            feature.append(uid)\n",
    "            feature.append(pid)\n",
    "            #Users\n",
    "            feature.append(np.round(ordere_ratio_last_5,4))\n",
    "            feature.append(count_of_ones_after_first_one)\n",
    "            feature.append(count_of_zeros_after_first_one)\n",
    "            feature.append(one_exceed_zeros_count)\n",
    "            feature.append(len_of_ordersteak_after_first_one)\n",
    "            feature.append(np.round(reorder_ratio_after_first_one,4))\n",
    "            feature.append(Is_it_reordered)\n",
    "            feature.append(Is_the_first_one_last_order)\n",
    "            feature.append(Is_the_first_one_last_but_one_order)\n",
    "            feature.append(last_time_ordered)\n",
    "            feature.append(last_two_times_ordered)\n",
    "            feature.append(coun_greater_2)\n",
    "            feature.append(coun_greater_3)\n",
    "            \n",
    "            feature.append(first_index_of_one)\n",
    "            feature.append(np.round(orders_per_day,4))\n",
    "            feature.append(np.round(days_taken_for_product_reorders_avg,4))\n",
    "            feature.append(np.round(days_remain_to_probable_buy,4))\n",
    "            feature.append(np.round(ordperday_order_ratio,4))\n",
    "            feature.append(np.round(order_steak_days_weighted5_1,4))\n",
    "            feature.append(np.round(order_steak_days_weighted5_2,4))\n",
    "            feature.append(np.round(median_days_no_buy5,4))\n",
    "            feature.append(np.round(max_days_no_buy5,4))\n",
    "            feature.append(np.round(days_spent_no_buy_last,4))\n",
    "            \n",
    "            \n",
    "            if (temp_train.empty == False):\n",
    "                reordered = 1\n",
    "            else:\n",
    "                reordered = 0\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "            \n",
    "           \n",
    "            feature.append(reordered)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            row_data.append(feature)\n",
    "    temp=pd.DataFrame(row_data,columns=columns23)\n",
    "    temp.to_csv('featured_data_temp2'+str(nocopy)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2nd set of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstprocess(test_users,nocopy):\n",
    "    row_data=[]\n",
    "    for uid in tqdm(test_users):\n",
    "        \n",
    "        oneuser=master_prior[master_prior['user_id']==uid]\n",
    "        \n",
    "        train_order_number=orders[(orders['user_id']==uid)]['order_number'].max()\n",
    "        trains_days_since_prior_order=int(orders[(orders['user_id']==uid) & (orders.order_number==train_order_number)]['days_since_prior_order'])\n",
    "        pids = pd.unique(oneuser['product_id'])\n",
    "        \n",
    "        user_tot_order=np.arange(1,oneuser['order_number'].max()+1)\n",
    "        #another feature related above one comes here\n",
    "\n",
    "        \n",
    "        for pid in pids:\n",
    "            feature=[]\n",
    "            reordered=0\n",
    "            \n",
    "            \n",
    "            oneuserproduct=oneuser[oneuser['product_id']==pid]\n",
    "    \n",
    "            user_pro_order=pd.unique(oneuserproduct['order_number'])\n",
    "            order_steak = [1 if i in user_pro_order  else 0 for i in user_tot_order]\n",
    "            \n",
    "\n",
    "            #product features\n",
    "            first_index_of_one=order_steak.index(1)\n",
    "            \n",
    "            order_steak_5=order_steak[-5:]\n",
    "            \n",
    "            order_steak_5=[int(i) for i in order_steak_5]\n",
    "\n",
    "            #\n",
    "            ordere_ratio_last_5=order_steak_5.count(1)/5\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            count_of_ones_after_first_one =order_steak.count(1)-1\n",
    "            count_of_zeros_after_first_one =order_steak[first_index_of_one:].count(0)\n",
    "            one_exceed_zeros_count=count_of_ones_after_first_one-count_of_zeros_after_first_one\n",
    "            len_of_ordersteak_after_first_one =len(order_steak[first_index_of_one:])\n",
    "            if(len_of_ordersteak_after_first_one!=0):\n",
    "                reorder_ratio_after_first_one = count_of_ones_after_first_one/len_of_ordersteak_after_first_one\n",
    "            else:\n",
    "                reorder_ratio_after_first_one=-0.5\n",
    "                \n",
    "            Is_it_reordered =order_steak[first_index_of_one:].count(1)-1\n",
    "            Is_the_first_one_last_order = 0\n",
    "            Is_the_first_one_last_but_one_order = 0\n",
    "            last_time_ordered=order_steak[-1:].count(1)\n",
    "            last_two_times_ordered=order_steak[-2:].count(1)\n",
    "            if(last_two_times_ordered==2):\n",
    "                last_two_times_ordered=1\n",
    "            else:\n",
    "                last_two_times_ordered=0\n",
    "    \n",
    "\n",
    "            if((len(order_steak)-1)==first_index_of_one):\n",
    "                Is_the_first_one_last_order=1\n",
    "            if((len(order_steak)-2)==first_index_of_one):\n",
    "                Is_the_first_one_last_but_one_order=1\n",
    "            \n",
    "            if(Is_it_reordered>=2):\n",
    "                coun_greater_2=1\n",
    "            else:\n",
    "                coun_greater_2=0\n",
    "            \n",
    "            \n",
    "            if(Is_it_reordered>=3):\n",
    "                coun_greater_3=1\n",
    "            else:\n",
    "                coun_greater_3=0\n",
    "\n",
    "            if(Is_it_reordered):\n",
    "            #find the sum of this with respect to all the products\n",
    "            #calculate total reorder probability here\n",
    "                Is_it_reordered=1\n",
    "            else:\n",
    "            #first time product only\n",
    "                Is_it_reordered=0\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            total_days_since_first_order=(oneuser.groupby(['order_number'])['days_since_prior_order'].aggregate('mean').reset_index().loc[first_index_of_one+1:]['days_since_prior_order'].sum())\n",
    "\n",
    "            if(total_days_since_first_order != 0):\n",
    "                orders_per_day=count_of_ones_after_first_one/total_days_since_first_order\n",
    "            else:\n",
    "                orders_per_day=-0.5\n",
    "\n",
    "    \n",
    "            if(count_of_ones_after_first_one != 0):\n",
    "                days_taken_for_product_reorders_avg = total_days_since_first_order/count_of_ones_after_first_one\n",
    "            else:\n",
    "                days_taken_for_product_reorders_avg=-0.5\n",
    "\n",
    "            if(days_taken_for_product_reorders_avg !=-0.5):\n",
    "                days_remain_to_probable_buy=int(days_taken_for_product_reorders_avg-trains_days_since_prior_order)\n",
    "            else:\n",
    "                days_remain_to_probable_buy = -0.5\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ordperday_order_ratio=orders_per_day*reorder_ratio_after_first_one\n",
    "            \n",
    "            days_list=orders[orders['user_id']==uid]['days_since_prior_order'].tolist()\n",
    "            days_list=days_list[1:][-5:]\n",
    "            order_steak5=order_steak[-5:]\n",
    "            \n",
    "            \n",
    "            if(sum(order_steak5)!=0):\n",
    "                first_occur_one=order_steak5.index(1)\n",
    "                if(sum(np.array(days_list)*0.01)!=0.0):\n",
    "                    order_steak_days_weighted5_1 = sum((np.arange(1,len(order_steak5)+1,1)/10)*order_steak5)/sum(np.array(days_list)*0.01)\n",
    "                else:\n",
    "                    order_steak_days_weighted5_1=-0.5\n",
    "                if(sum(np.array(days_list[first_occur_one:])*0.01) != 0.0):\n",
    "                    order_steak_days_weighted5_2 = sum((np.arange(1,len(order_steak5)+1,1)/10)*order_steak5)/sum(np.array(days_list[first_occur_one:])*0.01)\n",
    "                else:\n",
    "                    order_steak_days_weighted5_2=-0.5\n",
    "            else:\n",
    "                order_steak_days_weighted5_1=0\n",
    "                order_steak_days_weighted5_2=0\n",
    "                \n",
    "            \n",
    "            \n",
    "            listOfSumDays=[]\n",
    "            index_one=[i for i,j in enumerate(order_steak5) if j==1]\n",
    "            for i in range(len(index_one)):\n",
    "                k=index_one[i:i+2]\n",
    "                if(len(k)==2):\n",
    "                    \n",
    "                    listOfSumDays.append(sum(days_list[-5:][k[0]:k[1]]))\n",
    "                else:\n",
    "                    listOfSumDays.append(sum(days_list[-5:][k[0]:]))\n",
    "                    \n",
    "            if(len(listOfSumDays)!=0):\n",
    "                median_days_no_buy5=np.median(listOfSumDays)\n",
    "                max_days_no_buy5=np.max(listOfSumDays)\n",
    "                days_spent_no_buy_last=listOfSumDays[-1:][0]\n",
    "            else:\n",
    "                median_days_no_buy5=-0.5\n",
    "                max_days_no_buy5=-0.5\n",
    "                days_spent_no_buy_last=-0.5\n",
    "    \n",
    "            feature.append(uid)\n",
    "            feature.append(pid)\n",
    "            #Users\n",
    "            feature.append(np.round(ordere_ratio_last_5,4))\n",
    "            feature.append(count_of_ones_after_first_one)\n",
    "            feature.append(count_of_zeros_after_first_one)\n",
    "            feature.append(one_exceed_zeros_count)\n",
    "            feature.append(len_of_ordersteak_after_first_one)\n",
    "            feature.append(np.round(reorder_ratio_after_first_one,4))\n",
    "            feature.append(Is_it_reordered)\n",
    "            feature.append(Is_the_first_one_last_order)\n",
    "            feature.append(Is_the_first_one_last_but_one_order)\n",
    "            feature.append(last_time_ordered)\n",
    "            feature.append(last_two_times_ordered)\n",
    "            feature.append(coun_greater_2)\n",
    "            feature.append(coun_greater_3)\n",
    "            \n",
    "            feature.append(first_index_of_one)\n",
    "            feature.append(np.round(orders_per_day,4))\n",
    "            feature.append(np.round(days_taken_for_product_reorders_avg,4))\n",
    "            feature.append(np.round(days_remain_to_probable_buy,4))\n",
    "            feature.append(np.round(ordperday_order_ratio,4))\n",
    "            feature.append(np.round(order_steak_days_weighted5_1,4))\n",
    "            feature.append(np.round(order_steak_days_weighted5_2,4))\n",
    "            feature.append(np.round(median_days_no_buy5,4))\n",
    "            feature.append(np.round(max_days_no_buy5,4))\n",
    "            feature.append(np.round(days_spent_no_buy_last,4))\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            row_data.append(feature)\n",
    "    temp=pd.DataFrame(row_data,columns=columns23)\n",
    "    temp.to_csv('featured_data_test2'+str(nocopy)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns23=['user_id','product_id','ordere_ratio_last_5','count_of_ones_after_first_one','count_of_zeros_after_first_one','one_exceed_zeros_count','len_of_ordersteak_after_first_one','reorder_ratio_after_first_one','Is_it_reordered','Is_the_first_one_last_order','Is_the_first_one_last_but_one_order','last_time_ordered','last_two_times_ordered','coun_greater_2','coun_greater_3','first_index_of_one','orders_per_day','days_taken_for_product_reorders_avg','days_remain_to_probable_buy','ordperday_order_ratio','order_steak_days_weighted5_1','order_steak_days_weighted5_2','median_days_no_buy5','max_days_no_buy5','days_spent_no_buy_last']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd set of featues  reorder probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assue that if a product is ordered it is represented by 1 else 0\n",
    "<ol>\n",
    "<li>'weighted_bin1':product is ordered in last but 4th transaction multiplied by 0.1;for example if was ordered it is 1*0.1</li>\n",
    "<li>'weighted_bin2':product is ordered in last but 3rd transaction multiplied by 0.2</li>\n",
    "<li>'weighted_bin3':product is ordered in last but 2nd transaction multiplied by 0.3</li>\n",
    "<li>'weighted_bin4':product is ordered in last but 1st transaction multiplied by 0.4</li>\n",
    "<li>'weighted_bin5':product is ordered in last but 1st transaction multiplied by 0.5;i.e more recent transactions given more weightage</li>\n",
    "<li>department_reorder_probability:What is the departmentwise reorder probability of the product,it is differant from reorder ratio</li>\n",
    "<li>product_reorder_probability:What is the productwise reorder probability</li>\n",
    "<li>aisle_reorder_probability:what is the departmentwise reorder probability of the product</li>\n",
    "<li>days_gap_reorder_probability:</li>\n",
    "<li>orderhour_reorder_probability:What is the hourwise reorder probability of the product</li>\n",
    "<li>cart_reorder_probability:Reorder probability of the product based on average add to cart number of the product for a perticular user</li>\n",
    "<li>cart_reorder_probability_universal:Reorder probability of the product based on average add to cart number of the product for all users</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading probability features to create 3rd set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_test['weight_bin1']=feature_data_test['bin1']*0.1\n",
    "feature_data_test['weight_bin2']=feature_data_test['bin2']*0.1\n",
    "feature_data_test['weight_bin3']=feature_data_test['bin3']*0.1\n",
    "feature_data_test['weight_bin4']=feature_data_test['bin4']*0.1\n",
    "feature_data_test['weight_bin5']=feature_data_test['bin5']*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cart_reorder_prob=pd.read_csv('add_cart_reorder_prob.csv')\n",
    "add_cart_reorder_prob1=pd.read_csv('add_cart_reorder_prob.csv').rename(columns={'probability':'cart_reorder_probability_univesal'})\n",
    "aisle_probability=pd.read_csv('aisle_probability.csv').rename(columns={'probability':'aisle_reorder_probability'})\n",
    "department_probability = pd.read_csv('department_probability.csv').rename(columns={'probability':'department_reorder_probability'})\n",
    "days_since_probability=pd.read_csv('days_since_probability.csv').rename(columns={'probability':'days_gap_reorder_probability'})\n",
    "orderhour_probability=pd.read_csv('orderhour_probability.csv').rename(columns={'probability':'orderhour_reorder_probability'})\n",
    "product_probability=pd.read_csv('product_probability.csv').rename(columns={'probability':'product_reorder_probability'})\n",
    "department_probability.drop(['department'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_test=pd.merge(feature_data_test,department_probability,how='inner',on=['department_id'])\n",
    "feature_data_test=pd.merge(feature_data_test,product_probability,how='inner',on=['product_id'])\n",
    "feature_data_test=pd.merge(feature_data_test,aisle_probability,how='inner',on=['aisle_id'])\n",
    "feature_data_test=pd.merge(feature_data_test,days_since_probability,how='inner',on=['days_since_prior_order'])\n",
    "feature_data_test=pd.merge(feature_data_test,orderhour_probability,how='inner',on=['order_hour_of_day'])\n",
    "feature_data_test=pd.merge(feature_data_test,add_cart_reorder_prob,how='inner',left_on='product_add_order_local',right_on='add_to_cart_order')\n",
    "feature_data_test=pd.merge(feature_data_test,add_cart_reorder_prob1,how='inner',left_on='product_add_order_universal',right_on='add_to_cart_order')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing to featurize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YG12PJJtXIap"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 232 ms, sys: 249 ms, total: 481 ms\n",
      "Wall time: 1h 47min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from multiprocessing import Process\n",
    "import multiprocessing\n",
    "def main():\n",
    "    p=[None]*8\n",
    "    #the below code is used for multiprogramming\n",
    "    #the number of process depends upon the number of cores present System\n",
    "    #process is used to call multiprogramming\n",
    "    manager=multiprocessing.Manager() \t\n",
    "    for i in range(0,8):\n",
    "        p[i]=Process(target = firstprocess,args = (test_users_list[i],i,))\n",
    "    \n",
    "    \n",
    "    #p1.start() is used to start the thread execution\n",
    "    for i in range(0,8):\n",
    "        p[i].start()\n",
    "    \n",
    "    #After completion all the threads are joined\n",
    "    for i in range(0,8):\n",
    "        p[i].join()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Features are summarized here</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train78features=pd.read_csv('final_78_features.csv')\n",
    "test78features=pd.read_csv('feature_data_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TrainFeatues are consuming around 4GB data and test data is around 2GB till now. Created the features in Google cloud with 8 processors and 32GB RAM . With 8 processors data creation took around 12 hours. Found out that  XGBoost gets stuck if we take all features once into RAM. In lightgbm data was fitting well and extremely fast compared to xgboost. But hyper tuning is also difficult with this much amount of data. So will try to hyper tune row sampling and columnsampling multiple times and get the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8474661, 79)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train78features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>max_order_number</th>\n",
       "      <th>avg_products_per_ordered_5</th>\n",
       "      <th>avg_products_per_ordered</th>\n",
       "      <th>avg_times_product</th>\n",
       "      <th>max_times_product</th>\n",
       "      <th>max_reorder_any_product</th>\n",
       "      <th>total_reorder_ratio</th>\n",
       "      <th>product_add_order_universal</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_bin4</th>\n",
       "      <th>weight_bin5</th>\n",
       "      <th>department_reorder_probability</th>\n",
       "      <th>product_reorder_probability</th>\n",
       "      <th>aisle_reorder_probability</th>\n",
       "      <th>days_gap_reorder_probability</th>\n",
       "      <th>orderhour_reorder_probability</th>\n",
       "      <th>cart_reorder_probability</th>\n",
       "      <th>cart_reorder_probability_univesal</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.9000</td>\n",
       "      <td>3.2778</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.356632</td>\n",
       "      <td>0.470259</td>\n",
       "      <td>0.349587</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>0.281428</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166234</td>\n",
       "      <td>196</td>\n",
       "      <td>23</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6522</td>\n",
       "      <td>6.1000</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356632</td>\n",
       "      <td>0.470259</td>\n",
       "      <td>0.349587</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>0.281428</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176205</td>\n",
       "      <td>196</td>\n",
       "      <td>25</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.1600</td>\n",
       "      <td>3.1765</td>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.685</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356632</td>\n",
       "      <td>0.470259</td>\n",
       "      <td>0.349587</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>0.281428</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183553</td>\n",
       "      <td>196</td>\n",
       "      <td>28</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.2143</td>\n",
       "      <td>2.3077</td>\n",
       "      <td>11</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.567</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356632</td>\n",
       "      <td>0.470259</td>\n",
       "      <td>0.349587</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>0.281428</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175812</td>\n",
       "      <td>40939</td>\n",
       "      <td>15</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7333</td>\n",
       "      <td>1.4444</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.308</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.356632</td>\n",
       "      <td>0.363946</td>\n",
       "      <td>0.439581</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>0.281428</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  max_order_number  avg_products_per_ordered_5  \\\n",
       "0        1         196                10                         6.0   \n",
       "1   166234         196                23                         2.6   \n",
       "2   176205         196                25                         1.4   \n",
       "3   183553         196                28                         2.4   \n",
       "4   175812       40939                15                         1.6   \n",
       "\n",
       "   avg_products_per_ordered  avg_times_product  max_times_product  \\\n",
       "0                    5.9000             3.2778                 10   \n",
       "1                    2.6522             6.1000                 18   \n",
       "2                    2.1600             3.1765                 11   \n",
       "3                    3.2143             2.3077                 11   \n",
       "4                    1.7333             1.4444                  3   \n",
       "\n",
       "   max_reorder_any_product  total_reorder_ratio  product_add_order_universal  \\\n",
       "0                      1.0                0.695                            3   \n",
       "1                      1.0                0.836                            3   \n",
       "2                      0.6                0.685                            3   \n",
       "3                      0.4                0.567                            3   \n",
       "4                      0.2                0.308                            3   \n",
       "\n",
       "   ...  weight_bin4  weight_bin5  department_reorder_probability  \\\n",
       "0  ...          0.4          0.5                        0.356632   \n",
       "1  ...          0.0          0.0                        0.356632   \n",
       "2  ...          0.0          0.0                        0.356632   \n",
       "3  ...          0.0          0.0                        0.356632   \n",
       "4  ...          0.0          0.5                        0.356632   \n",
       "\n",
       "   product_reorder_probability  aisle_reorder_probability  \\\n",
       "0                     0.470259                   0.349587   \n",
       "1                     0.470259                   0.349587   \n",
       "2                     0.470259                   0.349587   \n",
       "3                     0.470259                   0.349587   \n",
       "4                     0.363946                   0.439581   \n",
       "\n",
       "   days_gap_reorder_probability  orderhour_reorder_probability  \\\n",
       "0                        0.2952                       0.281428   \n",
       "1                        0.2952                       0.281428   \n",
       "2                        0.2952                       0.281428   \n",
       "3                        0.2952                       0.281428   \n",
       "4                        0.2952                       0.281428   \n",
       "\n",
       "   cart_reorder_probability  cart_reorder_probability_univesal  reordered  \n",
       "0                      0.37                           0.298406          1  \n",
       "1                      0.37                           0.298406          0  \n",
       "2                      0.37                           0.298406          0  \n",
       "3                      0.37                           0.298406          0  \n",
       "4                      0.37                           0.298406          0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train78features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4833292, 78)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test78features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>max_order_number</th>\n",
       "      <th>avg_products_per_ordered_5</th>\n",
       "      <th>avg_products_per_ordered</th>\n",
       "      <th>avg_times_product</th>\n",
       "      <th>max_times_product</th>\n",
       "      <th>max_reorder_any_product</th>\n",
       "      <th>total_reorder_ratio</th>\n",
       "      <th>product_add_order_universal</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_bin3</th>\n",
       "      <th>weight_bin4</th>\n",
       "      <th>weight_bin5</th>\n",
       "      <th>department_reorder_probability</th>\n",
       "      <th>product_reorder_probability</th>\n",
       "      <th>aisle_reorder_probability</th>\n",
       "      <th>days_gap_reorder_probability</th>\n",
       "      <th>orderhour_reorder_probability</th>\n",
       "      <th>cart_reorder_probability</th>\n",
       "      <th>cart_reorder_probability_univesal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>47766</td>\n",
       "      <td>12</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.3333</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.309702</td>\n",
       "      <td>0.436097</td>\n",
       "      <td>0.393833</td>\n",
       "      <td>0.280343</td>\n",
       "      <td>0.265305</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>0.245529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38488</td>\n",
       "      <td>47766</td>\n",
       "      <td>5</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>10.8000</td>\n",
       "      <td>1.3171</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.241</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309702</td>\n",
       "      <td>0.436097</td>\n",
       "      <td>0.393833</td>\n",
       "      <td>0.280343</td>\n",
       "      <td>0.265305</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>0.245529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49686</td>\n",
       "      <td>47209</td>\n",
       "      <td>33</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>4.9697</td>\n",
       "      <td>1.9070</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.476</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309702</td>\n",
       "      <td>0.438232</td>\n",
       "      <td>0.393833</td>\n",
       "      <td>0.280343</td>\n",
       "      <td>0.265305</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>0.245529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87661</td>\n",
       "      <td>21288</td>\n",
       "      <td>3</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>14.6667</td>\n",
       "      <td>1.0732</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.068</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.309702</td>\n",
       "      <td>0.343467</td>\n",
       "      <td>0.393833</td>\n",
       "      <td>0.280343</td>\n",
       "      <td>0.265305</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>0.245529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199370</td>\n",
       "      <td>21288</td>\n",
       "      <td>9</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>10.2222</td>\n",
       "      <td>1.7358</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.424</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309702</td>\n",
       "      <td>0.343467</td>\n",
       "      <td>0.393833</td>\n",
       "      <td>0.280343</td>\n",
       "      <td>0.265305</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>0.245529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  max_order_number  avg_products_per_ordered_5  \\\n",
       "0        3       47766                12                    6.000000   \n",
       "1    38488       47766                 5                   10.800000   \n",
       "2    49686       47209                33                    6.600000   \n",
       "3    87661       21288                 3                   14.666667   \n",
       "4   199370       21288                 9                   11.200000   \n",
       "\n",
       "   avg_products_per_ordered  avg_times_product  max_times_product  \\\n",
       "0                    7.3333             2.6667                 10   \n",
       "1                   10.8000             1.3171                  3   \n",
       "2                    4.9697             1.9070                 22   \n",
       "3                   14.6667             1.0732                  2   \n",
       "4                   10.2222             1.7358                  6   \n",
       "\n",
       "   max_reorder_any_product  total_reorder_ratio  product_add_order_universal  \\\n",
       "0                      1.0                0.625                            6   \n",
       "1                      0.6                0.241                            6   \n",
       "2                      1.0                0.476                            6   \n",
       "3                      0.4                0.068                            6   \n",
       "4                      1.0                0.424                            6   \n",
       "\n",
       "   ...  weight_bin3  weight_bin4  weight_bin5  department_reorder_probability  \\\n",
       "0  ...          0.3          0.4          0.5                        0.309702   \n",
       "1  ...          0.0          0.4          0.0                        0.309702   \n",
       "2  ...          0.0          0.0          0.0                        0.309702   \n",
       "3  ...          0.3          0.0          1.0                        0.309702   \n",
       "4  ...          0.0          0.0          0.0                        0.309702   \n",
       "\n",
       "   product_reorder_probability  aisle_reorder_probability  \\\n",
       "0                     0.436097                   0.393833   \n",
       "1                     0.436097                   0.393833   \n",
       "2                     0.438232                   0.393833   \n",
       "3                     0.343467                   0.393833   \n",
       "4                     0.343467                   0.393833   \n",
       "\n",
       "   days_gap_reorder_probability  orderhour_reorder_probability  \\\n",
       "0                      0.280343                       0.265305   \n",
       "1                      0.280343                       0.265305   \n",
       "2                      0.280343                       0.265305   \n",
       "3                      0.280343                       0.265305   \n",
       "4                      0.280343                       0.265305   \n",
       "\n",
       "   cart_reorder_probability  cart_reorder_probability_univesal  \n",
       "0                  0.298406                           0.245529  \n",
       "1                  0.298406                           0.245529  \n",
       "2                  0.298406                           0.245529  \n",
       "3                  0.298406                           0.245529  \n",
       "4                  0.298406                           0.245529  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test78features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total 76 features are created for train and test . Here I have created features for test data already. As we do not have labes for test data , We have to check accuracy in kaggle only. For the case study temporarily I will devide 'train78features' into train and test , and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'product_id', 'max_order_number',\n",
       "       'avg_products_per_ordered_5', 'avg_products_per_ordered',\n",
       "       'avg_times_product', 'max_times_product', 'max_reorder_any_product',\n",
       "       'total_reorder_ratio', 'product_add_order_universal',\n",
       "       'reorder_ratio_cart_universal', 'product_add_order_local',\n",
       "       'reorder_ratio_cart_local', 'product_time_order', 'order_dow',\n",
       "       'order_hour_of_day', 'days_since_prior_order',\n",
       "       'reorder_ratio_user_hour', 'reorder_ratio_all_user_hour',\n",
       "       'reorder_ratio_user_week', 'order_ratio', 'department_id', 'aisle_id',\n",
       "       'pf', 'af', 'df', 'dep_reorder_ratio', 'aisle_reorder_ratio',\n",
       "       'product_reorder_ratio', 'ordered_last_5', 'atco', 'dspo', 'ohod',\n",
       "       'odow', 'max_no_purchase', 'tot_chance_buy', 'median_n5', 'bin1',\n",
       "       'bin2', 'bin3', 'bin4', 'bin5', 'bin2dec_order_steak5',\n",
       "       'ordere_ratio_last_5', 'count_of_ones_after_first_one',\n",
       "       'count_of_zeros_after_first_one', 'one_exceed_zeros_count',\n",
       "       'len_of_ordersteak_after_first_one', 'reorder_ratio_after_first_one',\n",
       "       'Is_it_reordered', 'Is_the_first_one_last_order',\n",
       "       'Is_the_first_one_last_but_one_order', 'last_time_ordered',\n",
       "       'last_two_times_ordered', 'coun_greater_2', 'coun_greater_3',\n",
       "       'first_index_of_one', 'orders_per_day',\n",
       "       'days_taken_for_product_reorders_avg', 'days_remain_to_probable_buy',\n",
       "       'ordperday_order_ratio', 'order_steak_days_weighted5_1',\n",
       "       'order_steak_days_weighted5_2', 'median_days_no_buy5',\n",
       "       'max_days_no_buy5', 'days_spent_no_buy_last', 'weight_bin1',\n",
       "       'weight_bin2', 'weight_bin3', 'weight_bin4', 'weight_bin5',\n",
       "       'department_reorder_probability', 'product_reorder_probability',\n",
       "       'aisle_reorder_probability', 'days_gap_reorder_probability',\n",
       "       'orderhour_reorder_probability', 'cart_reorder_probability',\n",
       "       'cart_reorder_probability_univesal', 'reordered'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train78features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature summarization(total features =76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red\">Assumptions.</p><br>\n",
    "<ul>\n",
    "<li>Assume that Users products presence in all the orders is 0010101010, It means total 10 orders were place by the user till now. Out of which 3rd 5th and 7th and 9th orders conatain the product</li>.<br>\n",
    "\n",
    "<li>So in his last five orders, product's ordered or not ordered sequence is 01010 .That \n",
    "means User in his last five orders , ordered the product only in 2nd and 4th transaction</li><br>\n",
    "\n",
    "<li>Assume that if a product is ordered it is represented by 1 else 0</li><br>\n",
    "</ul>\n",
    "\n",
    "<ol>\n",
    "<li>max_order_number = latest order number ordered by the user </li>\n",
    "<li>avg_products_per_order5 = average number of products ordered in user's last five orders</li>\n",
    "<li>avg_products_per_ordered = average number of products per order </li>\n",
    "<li>avg_times_product =  number of  times a product is ordered on an average by the user</li>\n",
    "<li>max_times_product  =  maximun times any product is ordered by the user</li>\n",
    "<li>max_reorder_any_product = maximum reorder ratio of any product by the user;Here reorders refers number of reorders in user's total orders</li>\n",
    "    \n",
    "<li>reorder_ratio = total reorder ratio of that product</li>\n",
    "    \n",
    "<li>product_add_order_universal = product's all user average add to cart number</li>\n",
    "<li>reorder_ratio_cart_universal = for a perticular add to cart number what is the reorder ratio for all users</li>\n",
    "    \n",
    "<li>product_add_order_local = what is the product's mean add_to_cart_order number for a perticular user?</li>\n",
    "<li>reorder_ratio_cart_local = For a perticular user and perticular add to cart number what is the reorder ratio?</li>\n",
    "    \n",
    "<li>product_time_order = Usually at what time product is ordered for all users</li>\n",
    "<li>order_dow = what day of the week user ordered</li>\n",
    "<li> order_hour_of_day = In which hour user ordered</li>\n",
    "<li> days_since_prior_order = how many days elapsed since last order</li>\n",
    "    \n",
    "<li>reorder_ratio_user_hour = what is the reorder ratio of the user at a perticular hour</li>\n",
    "<li>reorder_ratio_all_user_hour = how much in ratio all users order at a perticular hour</li>\n",
    "<li>reorder_ratio_user_week = how much in ratio user reorders on a perticular day of the week</li>\n",
    "<li>order_ratio=ratio of how many times user bought the product in his total orders</li>\n",
    "\n",
    "<li>department_id of the product</li>\n",
    "<li>aisle_id of the product</li>\n",
    "<li>pf= product frequency,ie it indicates the ratio of perticular product count to all product count</li>\n",
    "<li>af= (similar to product frequency)aisle frequency</li>\n",
    "<li>df =(similar to product frequency)department frequency</li>\n",
    "<li>dep_reorder_ratio=Reorder ratio of a perticular department for all users</li>\n",
    "<li>aisle_reorder_ratio=Reorder ratio of a perticular aisle for all users</li>\n",
    "<li>product_reorder_ratio=Reorder ratio of a perticular product for all users</li>\n",
    "<li>ordered_last_5 = how many times user ordered product in his last five orders</li>\n",
    "<li>atco = product's average add to cart order in users last 5 orders</li>\n",
    "<li>dspo = number of days it took to order this product from previous order of any product</li>\n",
    "<li>ohod = average order hour in last few orders</li>\n",
    "<li>odow = average day of week order was placed  in last few orders</li>\n",
    "<li>max_no_purchase = maximum number of days spent without buying, by the user.</li>\n",
    "<li>tot_chance_buy = once a perticular product is bought for the first time how orders user did?</li>\n",
    "<li>median_n5 = Median number of days user has gone without buying the product after the previous order</li>\n",
    "<li>order_steak_5='bin1',bin2','bin3,'bin4','bin5','bin6'= 'ordered'  or  'not ordered' product binary sequence in last five orders</li>\n",
    "<li>bin2dec= decimal reprecentation of the previous feature(order_steak_5)</li>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "<li>ordere_ratio_last_5:It is just  order ratio : Indicating on how many orders in last 5 orders contain product.In the above example it is 2/5 </li>\n",
    "<li>count_of_ones_after_first_one:How many times product reordered after product is ordered in last 5 transaction . In the example it is 3. </li>\n",
    "<li>count_of_zeros_after_first_one:How many times product reordered after product is not ordered in last 5 transaction . In the example it is 4</li>\n",
    "<li>one_exceed_zeros_count:how many times product ordered exceeds not ordered after order of the product is placed for the first time.In the above example it is -1</li>\n",
    "<li>len_of_ordersteak_after_first_one:reorder_ratio_after_first_one:How many orders were there after product is placed for the first time . In the above example it is 7</li>\n",
    "<li>reorder_ratio_after_first_one:How many orders were there after product is placed for the first time . In the above example it is 7</li>\n",
    "<li>reorder_ratio_after_first_one:In the above example it is 3/7</li>\n",
    "<li>Is_it_reordered:This variables tells if the product is reordered atleast once after it is ordered for the first time.'1'='YES' for our example</li>\n",
    "<li>Is_the_first_one_last_order:Is the product ordered only in the previous order. Answer is 0 ='No' for our example, For sequence 0000001 answer is 'YES'</li>\n",
    "<li>Is_the_first_one_last_but_one_order : Is the product ordered only in the last but one order. Answer is 0 ='No' for our example,For sequence 00010 or 00011 it is 'YES'</li>\n",
    "<li>last_time_ordered:Wheather the product was ordered last time ,For our example it is 'NO'</li>\n",
    "<li>last_two_times_ordered:Wheather the product was ordered last two times ?</li>\n",
    "<li>coun_greater_2:Was the product reordered more than two times? 'YES' for our example</li>\n",
    "<li>coun_greater_3:Was the product reordered more than three times? 'YES' for our example</li>\n",
    "<li>first_index_of_one: What is the order number that the product was ordered for the first time? Answer=3</li>\n",
    "<li>orders_per_day: It is the ratio of total orders to number of days took to make these many orders </li>\n",
    "<li>days_taken_for_product_reorders_avg:It is average days took for the user to make reorder of the product since his first order of the product</li>\n",
    "<li>days_remain_to_probable_buy:For example for the current order for which our task is to predict the reorder,If the days elapsed since last order is 14 days and for user it takes on an average 16 days to reorder the product ; days remaing for probable buy is 2 </li>\n",
    "<li>ordperday_order_ratio:It is multiplication of number of orders made per day and order ratio;These are the previous features</li>\n",
    "<li>order_steak_days_weighted5_1:It is the weighted average of number of order units happend in the last 5  to total number of days taken in last five orders. Here More recent reorders of the product gets more weightage </li>\n",
    "<li>order_steak_days_weighted5_2:It is the weighted average of number of order units happend to total number of days taken to make number of orders once the product was ordered for the first time. Here More recent reorders of the product gets more weightage</li>\n",
    "<li>median_days_no_buy5:In the last five transaction median number of days spent withour buying the product since product is ordered for the first time</li>\n",
    "<li>max_days_no_buy5:In the last five transaction maximum number of days spent withour buying the product since product is ordered for the first time</li>\n",
    "<li>days_spent_no_buy_last:What is the number of days already elapsed till now withour buying the product since product is ordered for the last time</li>\n",
    "    \n",
    "\n",
    "<li>'weighted_bin1':product is ordered in last but 4th transaction multiplied by 0.1;for example if was ordered it is 1*0.1</li>\n",
    "<li>'weighted_bin2':product is ordered in last but 3rd transaction multiplied by 0.2</li>\n",
    "<li>'weighted_bin3':product is ordered in last but 2nd transaction multiplied by 0.3</li>\n",
    "<li>'weighted_bin4':product is ordered in last but 1st transaction multiplied by 0.4</li>\n",
    "<li>'weighted_bin5':product is ordered in last but 1st transaction multiplied by 0.5;i.e more recent transactions given more weightage</li>\n",
    "<li>department_reorder_probability:What is the departmentwise reorder probability of the product,it is differant from reorder ratio</li>\n",
    "<li>product_reorder_probability:What is the productwise reorder probability</li>\n",
    "<li>aisle_reorder_probability:what is the departmentwise reorder probability of the product</li>\n",
    "<li>days_gap_reorder_probability:</li>\n",
    "<li>orderhour_reorder_probability:What is the hourwise reorder probability of the product</li>\n",
    "<li>cart_reorder_probability:Reorder probability of the product based on average add to cart number of the product for a perticular user</li>\n",
    "<li>cart_reorder_probability_universal:Reorder probability of the product based on average add to cart number of the product for all users</li>\n",
    "<li>reordered:It is our target label. It will tesll wheather the product is reordered or not for train data. When we combine designed features with the given train information propertly we will get this data. </li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">Referances made</p> \n",
    "\n",
    "kaggle competetion url:https://www.kaggle.com/c/instacart-market-basket-analysis/discussion/<br>\n",
    "seaborn:https://seaborn.pydata.org/generated/seaborn.barplot.html <br>\n",
    "pandas:https://pandas.pydata.org/pandas-docs/ <br>\n",
    "numpy:https://numpy.org/<br>\n",
    "winners interview:https://medium.com/kaggle-blog/instacart-market-basket-analysis-feda2700cded\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONjgnx55UlKWJxmOiOsVsL",
   "collapsed_sections": [],
   "name": "Featurization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
